\documentclass[../Main.tex]{subfiles}

\begin{document}
\chapter{Независимые события}

\section{Определение независимых событий}

] A, B - случайные события.
\rmk{Элементы \(\sigma-\)алгебры \(\mathfrak{A}\)}
\clmp{Ограничения к 1 определению независимости событий}{\(P(A) > 0, \ P(B) > 0\)}

\defn{Независимые события 1}{
Если 
\begin{equation*}
    \left\{ \begin{aligned} 
      P(A) &= P(A/_B)\\
      P(B) &= P(B/_A)
    \end{aligned} \right.
\end{equation*}
то такие события называются стохастически независимыми.
}

\defn{Независимые события 2}{
Если \(P(AB) = P(A) \cdot P(B),\) то такие события называются стохастически независимыми.
}
\defn{Принцип независимости}{
Из физической независимости следует стохастическая независимость. Обратное, вообще говоря, неверно.
}

Как правило, предположение о независимости упрощает выкладки и модель.

\rmkb{Независимость и несовместность НЕ связаны!}

Пусть \((\Omega, \mathfrak{A}, P) \ - \ \) вероятностное пространство.

\(A, B \in \mathfrak{A}, P(B) > 0 \rightarrow \)

\fact{Пусть A и B - независимые события, тогда:
\begin{enumerate}
    \item \(\overline{A}\) и \(B\),
    \item \(A\) и \(\overline{B}\),
    \item \(\overline{A}\) и \(\overline{B}\)
\end{enumerate}
- независимые события.
}
\rmk{Замена события на противоположное не влияет на независимость}
\pf{ 
1) \(B = A \cdot B + \overline{A} \cdot B \Rightarrow P(B) = P(A \cdot B) + P (\overline{A} \cdot B)\), так как события несовместные. Поскольку события A и B независимые, то
\[P(A \cdot B) = P(A) \ \cdot \ P(B) \]
тогда \(P(\overline{A}\cdot B) = P(B) \cdot (1-P(A)) = P(B) \cdot P(\overline{A})\).

2) \(A = A \cdot B + \overline{B} \cdot A \Rightarrow P(A) = P(A \cdot B) + P (\overline{B} \cdot A)\), так как события несовместные. Поскольку события A и B независимые, то
\[P(A \cdot B) = P(A) \ \cdot \ P(B) \]
тогда \(P(\overline{B}\cdot A) = P(A) \cdot (1-P(B)) = P(A) \cdot P(\overline{B})\).

3) Вероятность дополнения: \(P(\overline{A} \cdot \overline{B}) = 1 - P(A + B)\).
\(P(A + B) = P(A) + P(B) - P(A \cdot B)\). 

Так как события A и B независимые, то \(P(AB) = P(A) \cdot P(B) \Rightarrow P(A + B) = P(A) + P(B) - P(A) \cdot P(B)\). Подставим это в выражение для 
\(P(\overline{A} \cdot \overline{B}):\)
\[P(\overline{A} \cdot \overline{B}) = 1 - (P(A) + P(B) - P(A) \cdot P(B)) = 1 - P(A) - P(B) + P(A) \cdot P(B)\]
По определению противоположного события:
\begin{equation*}
    \begin{aligned} 
        P(\overline{A}) = 1 - P(A) \\
        P(\overline{B}) = 1 - P(B)
    \end{aligned}
\end{equation*}
Посчитаем их произведение:
\[P(\overline{A}) \cdot P(\overline{B}) = (1 - (P(A)) \cdot (1 - P(B)) = 1 - P(A) - P(B) + P(A) \cdot P(B) \]
И получаем, что \(P(\overline{A} \cdot \overline{B})=P(\overline{A}) \cdot P(\overline{B})\), ч.т.д.
}

\defn{Независимые в совокупности события}{
Для любого подмножества таких событий вероятность произведения равно произведению вероятностей.

\(\{A_i\}, i \in \{1, \dots, n \} \Rightarrow \forall \ 2 \leq k \leq n: \forall i_1, \dots, i_k \in \{1, \dots, n\}: P(A_i_1 \cdot \dotsc \cdot A_i_k) = P(A_i_1) \cdot \dotsc \cdot P(A_i_k).\)

\(i_1, \dotsc, i_k\) - уникальны.
}

\defn{Попарно независимое семейство событий}{
Такое семейство событий, для которых каждая пара событий независима друг от друга.

\(]\{A_i\}, i \in \{1, \dotsc, n\}. \ \forall \ i,j: i\neq j:\)
\(P(A_i \cdot A_j) = P(A_i) \cdot P(A_j) \)
}

\rmkb{
Из попарной независимости не следует независимость в совокупности.

------------------------------------------------------------------------------------------------------------------------------------------------

К тому же, попарная независимость — это когда каждая пара событий независима, но не обязательно все события вместе, а полная независимость — это когда любые подмножества событий независимы, включая пересечения любых семейств этих событий.
}

\exm{1}{
У нас есть числа 1, 6, 10 и 15.

Рассмотрим следующие события:

A - число делится на 2.

B - число делится на 3.

C - число делится на 5.

Вычислим вероятности:
P(A) = 1/2, P(B) = 1/2, P(C) = 1/2.

Проверим на попарную независимость:

\(P(AB) = 1/4 = P(A) \cdot P(B) \Rightarrow\) независимы.

\(P(BC) = 1/4 = P(B) \cdot P(C) \Rightarrow\) независимы.

\(P(AC) = 1/4 = P(A) \cdot P(C) \Rightarrow\) независимы.

Значит, все наши события \textbf{попарно} независимы. А теперь проверим на независимость \textbf{в совокупности}:

\(P(A \cdot B \cdot C) = 0 \neq 1/8\). У нас нет таких чисел, которые бы делились сразу на 2, 3 и 5. Так что наши события независимы попарно, но не в совокупности.
}

\section{Про физическую и стохастическую независимость}

\exm{2}{
У нас есть колода из 52 карт (без джокеров). Рассмотрим следующие события и из вероятности:

P(A) = 4/52 - вытащили туз;

P(B) = 1/4 - вытащили бубновую масть.

Тогда \(P(AB) = \dfrac{1}{52} = \dfrac{4 \cdot 1}{52 \cdot 4} \Rightarrow\) события независимы.

А теперь подкинем джокера и пересчитаем:

P(A) = 4/53 - вытащили туз;

P(B) = 13/53 - вытащили бубновую масть.

P(AB) - бубновый туз, один из 53 карт, но \(P(A \cdot B) = \dfrac{4 \cdot 13}{53 \cdot 53} \Rightarrow\) события зависимы.

Что доказывает этот пример? Для физической независимости добавление джокера не изменило бы независимость. А значит, что стохастическая независимость \(\nRightarrow\) физическая независимость.
}

\section{Последовательность независимых событий}

Рассмотрим семейство вероятностных пространств \(M = (\Omega, \mathfrak{A}, P): \forall \ 1 \leq k \leq n: M_k = (\Omega_k, \mathfrak{A}_k, P_k)\).

Множество элементарных исходов \(\Omega = \Omega_1 \cdot \dotsc \cdot \Omega_n\) - прямое произведение.

\(\mathfrak{A} \ -\) сигма-алгебра.

\(P \ -\) вероятностная мера.

\(\omega = (\omega_1, \dotsc, \omega_n) \in \Omega\ -\) множество элементарных исходов.

Событие \( A (\in \mathfrak{A}) = (A_1 \times \dotsc \times A_n) \ -\) набор векторов.

\(P(\omega) = P_1(\omega_1) \cdot \dotsc \cdot P_n(\omega_n ) \ -\) вероятность события = произведение вероятностей.

\(P(A) = P(\omega \in A) = \underset{\omega \in A}{\sum}P(\omega) = \underset{(\omega_1 \dotsc \omega_n)\in A}{\sum}P_1(\omega_1) \cdot \dotsc \cdot P_n(\omega_n)\).

Можно сказать, что таким образом построенная модель является вероятностным пространством.

\section{Схема Бернулли, или биномиальная схема}

\(\Omega_k = \{0,1\} \ \forall k = \overline{1,n}\).

\(P_k(1) = p, P_k(0) = 1-p (= q) \ \forall k = \overline{1,n}\).

Мы получим последовательность независимых вероятностных пространств.

Обозначим p = успех, q = неудача. Вероятность успеха \(\forall \ \Omega_k\) одна и та же и равна p.

\((\Omega) \ -\) бинарный (состоящий из 0 и 1) вектор длины n.

Обозначим число единиц в векторе \(M_k = k\).

\thmp{Теорема Бернулли}{\(P(M(\omega) = k) = C_n^k \cdot p^k \cdot (1-p)^{n-k}\)}{
    Рассмотрим \(p^k \cdot (1-p)^{n-k}\). По определению вероятностной меры:

    \(p^k \ -\) сколько единиц, \((1-p)^{n-k} \ -\) сколько нулей.

    Вероятность взять вектор с нужным числом единиц - число сочетаний \(С_n^k\).
    
}
\clm{к теореме Бернулли}{
    \begin{enumerate}
        \item n независимых испытаний;
        \item 2 исхода у каждого испытания;
        \item вероятность успеха не меняется от опыта к опыту.
    \end{enumerate}
}
\exm{с сервером}{
Построим упрощенную модель сервера, где величина промежутка времени \(\Delta t\) вмещает в себя только одно совершение (или несовершение) обращения к серверу. Схема Бернулли позволит вычислить количество совершенных обращений.
}

Минус биномиального распределения заключается в том, что можно рассмотреть всего два исхода. Но этот недостаток компенсирует полиномиальное распределение.

\section{Полиномиальное распределение}

\(\Omega_k = \{1, \dotsc, l\} \ \forall k = \overline{1,n}\).

\(\omega = (\omega_1, \dotsc, \omega_n)\).

\(P_k(m) = P_m \ \forall m = \overline{1,l}\), т.е. вероятность не меняется от опыта к опыту.

Обозначим за \(n_1 = 1, n_2 = 2, \dotsc, n_l = l\), где \(n_i = i\) - количество испытаний, где выпало число i, и \(\overset{l}{\underset{i = 1}{\sum}} n_i = n\) - количество испытаний.

Тогда вычисление вероятности события A вычисляется по формуле:

\[P(A) = \dfrac{n!}{n_1! \cdot \dotsc \cdot n_l!} \cdot (P_1)^{n_1} \cdot \dotsc \cdot (P_l)^{n_l}.\]

\clm{к полиномиальной схеме}{
\begin{enumerate}
    \item последовательность из n независимых испытаний;
    \item l исходов у каждого испытания;
    \item вероятность всех исходов не меняется от опыта к опыту.
\end{enumerate}
}

\exm{про кубик}{
10 испытаний, цифры 5 и число 2 выпали трижды, цифра 6 выпала четырежды. Вычислить вероятность этого события.

\(P(A) = \dfrac{10!}{3!4!3!} \cdot (\frac{1}{6})^3 \cdot (\frac{1}{6})^4 \cdot (\frac{1}{6})^3 = \dfrac{700}{6^9}\).
}
 
\end{document}