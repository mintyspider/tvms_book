\documentclass[../Main.tex]{subfiles}
\begin{document}
\chapter{Математическое ожидание}

\section{Определение математического ожидания}

\(\xi \{x_i, \mathbb{P}_i\}, i \in I\)

\(\mathbb{F}_\xi (x)=\mathbb{P}(\xi < x)\)

\defn{Математическое ожидание}{
Сумма произведений значений случайной величины на её вероятность.
}

\(\mathbb{M}_\xi = \begin{cases} \underset{i \in I}{\sum}x_i \mathbb{P}_i \\ \overset{+\infty}{\underset{-\infty}{\int}}x \rho(x) dx \end{cases}\)

\rmkb{Необходимое условие: математическое ожидание существует, если интеграл или ряд сходится абсолютно}

В физике математическое ожидание - среднее или центр тяжести.

У Бернулли = 0,5, посередине между принимаемыми значениями.

\rmkb{Математическое ожидание может равняться \(+\infty\)}

] \(2,\ 2^2,\ 2^3,\ 2^i\ - \xi,\ \frac{1}{2},\ \frac{1}{4},\ \frac{1}{8},\ \frac{1}{2^i}\)

\(\underset{i=1}{\overset{\infty}{\sum}}\mathbb{P}_i = 1 = \dfrac{\frac{1}{2}}{1-\frac{1}{2}}\)

\(\mathbb{M}_\xi = +\infty \cdot 1= +\infty\).

\exm{1}{
\(\mathbb{P}(\xi = k) = \frac{1}{2}\)

\(\mathbb{M}_\xi = 1\cdot \frac{1}{n} + 2 \cdot \frac{1}{n} + \dotsc + n \cdot \frac{1}{n} = \dfrac{n+1}{2}\)
}

\exm{2}{
\(\mathbb{P}(\xi = 0) = 1 - p, \ \mathbb{P}(\xi = 1) = p\)

\(\mathbb{M}_\xi = 0 \cdot (1-p) + 1 \cdot p = p\)
}

\subsection{Свойства математического ожидания}

\begin{enumerate}
    \item Математическое ожидание от суммы равно сумме математических ожиданий. \(\xi, \eta: \mathbb{M}_{[\xi + \eta] = \mathbb{M}_\xi + \mathbb{M}_\eta}\)

    \textbf{Доказательство:}
    
    1) Для непрерывной случайной величины: \(\xi, \ \rho_\xi(x), \eta, \rho_\eta(y)\ -\) случайные величины и их плотности.

    \(\mathbb{M}_{[\xi + \eta]} = \overset{+\infty}{\underset{-\infty}{\int}}\overset{+\infty}{\underset{-\infty}{\int}} (x+y) \rho_\xi(x)\cdot \rho_\eta (y) dxdy = \overset{+\infty}{\underset{-\infty}{\int}}x \rho_\xi(x)\overset{+\infty}{\underset{-\infty}{\int}}\rho_\eta (y)dydx + \overset{+\infty}{\underset{-\infty}{\int}} y \rho_\eta (y) \overset{+\infty}{\underset{-\infty}{\int}} \rho_\xi(x)dxdy = \overset{+\infty}{\underset{-\infty}{\int}}x \rho_\xi(x)dx + \overset{+\infty}{\underset{-\infty}{\int}} y \rho_\eta(y)dy = M_\xi + M_\eta\)

    2) Для дискретной случайной величины: \(\xi:(x_i, \mathbb{P}_i),\ i \in I;\ \eta:(y_j, \mathbb{Q}_j), j \in J\ -\) случайные величины и их законы распределения. 

    \(\mathbb{M}_{[\xi+\eta]}=\underset{i \in I}{\sum}\underset{j \in J}{\sum}(x_i + y_j)\mathbb{P}_\xi \mathbb{Q}_j = \underset{i \in I}{\sum}x_i \mathbb{P}_i\underset{j \in J}{\sum}\mathbb{Q}_j+\underset{j \in J}{\sum}y_j \mathbb{Q}_j \underset{i \in I}{\sum}\mathbb{P}_i = \underset{i \in I}{\sum}x_j \mathbb{P}_i + \underset{j \in J}{\sum}y_j \mathbb{Q}_j = \mathbb{M}_\xi + \mathbb{M}_\eta\).

    \item Если значение случайной величины неотрицательно, то математическое ожидание тоже неотрицательно: \(\xi \geq 0 \Rightarrow \mathbb{M}_\xi \geq 0\).

    \textbf{Доказательство:} Значение случайной величины неотрицательно по условию, вероятность ее выпадения, а также плотность неотрицательны по определению \Rightarrow Сумма для дискретной случайной величины и интеграл для непрерывной тоже неотрицательны.

    \item Если \(\xi > \eta\), то \(\mathbb{M}_\xi > \mathbb{M}_\eta\).

    \textbf{Доказательство:} \(\xi - \eta \geq 0\Rightarrow\) по свойству \(1^\circ\) \(\mathbb{M}_{[\xi-\eta]} \geq 0,\ \mathbb{M}_\xi - \mathbb{M}_\eta \geq 0\).

    \item Однородность математического ожидания \(\mathbb{M}_{[k \cdot \xi]} = k \mathbb{M}_\xi\)
    
    \textbf{Доказательство:} Однородность - возможность вынести и занести константу, по определению из под знака интеграла и суммы можно вынести константу.

    \item Линейность математического ожидания \(\mathbb{M}_{[a \cdot \xi + b \cdot \eta]} = a \mathbb{M}_\xi + b \mathbb{M}_\eta\)

    \textbf{Доказательство:} следует из свойств \(1^\circ\) и \(4^\circ\).

    \item Если \(\xi\) и \(\eta\) \textit{обязательно} независимы, то математическое ожидание от произведения равно произведению математических ожиданий.

    \textbf{Доказательство:} 

    1) В дискретном случае: \(\mathbb{M}_{\xi \eta} = \underset{k, n}{\sum}x_ky_n\mathbb{P}(\xi = x_k,\ \eta = y_n) = \underset{k}{\sum}x_k\mathbb{P}(\xi = x_k) \cdot \underset{n}{\sum}y_n\mathbb{P}(\eta = y_n) = M_\xi \cdot M_\eta\)

    ?? 2) В непрерывном случае: \(\mathbb{M}_{\xi \eta} = \overset{+\infty}{\underset{-\infty}{\int}}\overset{+\infty}{\underset{-\infty}{\int}}xy\ \rho(x,\ y)dxdy = \overset{+\infty}{\underset{-\infty}{\int}}\overset{+\infty}{\underset{-\infty}{\int}}x\rho(x)dx \cdot y\rho(y)dy =\overset{+\infty}{\underset{-\infty}{\int}}x\rho(x)dx \cdot \overset{+\infty}{\underset{-\infty}{\int}}y\rho(y)dy = M_\xi \cdot M_\eta\)

    \rmkb{Обратное неверно: из этого свойства не следует независимость случайных величин.}
\end{enumerate}

\exm{3}{
\(\xi : n, p.\ 0, 1, 2, \dotsc, n\)

\(\mathbb{P}_k = C_n^k \cdot p^k \cdot (1-p)^{n-k}\)

\(\mathbb{M}_\xi = \overset{n}{\underset{k-0}{\sum}}k \cdot C_n^k \cdot p^k \cdot (1-p)^{n-k}\)

Как это вычислить?

Пусть \(i_k \ -\) индикатор события, где 1 - в каждом испытании успех, и 0 - в ином случае. \(I_k(1) = p,\ I_k(0) = 1 - p\).

\(\mathbb{M}_{i_k} = 0 \cdot (1-p) + 1 \cdot p = p \ -\) собственно, случайная величина Бернулли.

Если число успехов \(= \mu \Rightarrow \mu = k  = i_1 + \dotsc + i_n, \ \xi = I_1 + \dotsc + I_n\).

\(\mathbb{M}_\xi = \mathbb{M}_{[I_1 + \dotsc + I_n]} = \overset{n}{\underset{k=1}{\sum}}M_{[I_k]} = n \cdot p\).

Получается, что физический смысл \(n \cdot p \ -\) среднее для большого числа событий.
}

\subsection{Закон Пуассона}

\exm{4}{
Параметр \(\lambda > 0. \ 0,1,2,\dots \ -\) значения. Вероятность, что случайная величина примет значение \(k \ - \ \mathbb{P}(k) = \mathbb{P}_k = \dfrac{\lambda^k \cdot e^{-\lambda}}{k!}\).
\rmk{Откуда это берется? Предельное распределение для биномиального распределения.}

Вероятность одного обращения \(= p\). Всего \(k\) обращений. Тогда вероятность \(\mathbb{P}(k = 1, \dots, n) = C_n^k\cdot p^k\cdot (1-p)^{n-k}\). При \(n \rightarrow \infty \Rightarrow p_n \rightarrow 0, \ n\cdot p \rightarrow \lambda\)
}

\thmp{Теорема Пуассона (про распределение редких событий)}{
\[C_n^k \cdot p^k \cdot (1-p)^{n-k} \underset{n \rightarrow \infty}{\rightarrow} \dfrac{\lambda^k \cdot e^{- \lambda}}{k!}\]

При \(n \rightarrow \infty\) биномиальное распределение устремляется к Пуассоновскому.
}{
Распишем подробнее левую часть:

\(\dfrac{n!}{k!(n-k)!} \cdot p^k \cdot (1-p)^{n-k} = \dfrac{n\cdot (n-1)\cdot \dotsc \cdot (n-k+1)}{k!} \cdot p^k \cdot (1-p)^{n-k}\).

Обозначим \(p_n = \dfrac{\lambda_n}{n}\) из \(p_n \cdot n = \lambda_n\). Подставим:

\(\dfrac{n\cdot (n-1)\cdot \dotsc \cdot (n-k+1)}{k!} \cdot {(\dfrac{\lambda_n}{n})}^k \cdot (1-\dfrac{\lambda_n}{n})^{n-k}\).

Поделим на n:

\((\dfrac{\lambda^k_n}{k!})\cdot 1 \cdot (1-\dfrac{1}{n}) \cdot \dotsc \cdot (1-\dfrac{k-1}{n}) \cdot (1-\dfrac{\lambda_n}{n})^n \cdot ?? (1-\dfrac{\lambda_n}{n})^k \underset{\underset{n \rightarrow \infty}{\lambda_n \rightarrow \lambda}}{\rightarrow} \dfrac{\lambda^k}{k!} \cdot 1 \cdot (1+\dfrac{-\lambda}{n})^n \cdot 1 = \dfrac{\lambda^k \cdot e^{-\lambda}}{k!}.\)

\rmk{
И еще одна вставочка:
Так как \(n \rightarrow + \infty\), дробь \(\dfrac{x}{\infty} \approx 0\), а \(e^{-\lambda}\) получается из второго замечательного предела \(\underset{n \rightarrow \infty}{lim}(1-\dfrac{x}{n})^n = e^x\).}
}

\rmkb{
Что мы получили? При условии, что \(p_n \rightarrow 0\), \(\lambda_n \rightarrow \lambda\) и \(n\cdot p \cdot q \leq 9\), если n большое, а p маленькое, вместо биномиального распределения можно пользоваться Пуассоновским. А если p не маленькое, то биномиальное распределение заменяется нормальным законом.
}

Математическое ожидание Пуассоновского распределения: \(\mathbb{M}_\xi = \lambda\).
\pf{
\(\mathbb{M}_\xi = \overset{\infty}{\underset{k=0}{\sum}}k \cdot \dfrac{\lambda^k \cdot e^{-\lambda}}{k!} = \lambda e^{-\lambda} \overset{\infty}{\underset{k=1}{\sum}} \dfrac{\lambda^{k-1}}{(k-1)!} = \overset{\infty}{\underset{k=0}{\sum}}\dfrac{\lambda^k}{k!} = \lambda e^{-\lambda} \cdot e^\lambda = \lambda.\)
}

\rmk{Если возникает вопрос про характеристики случайной величины, которая зависит от какого-то параметра, то наверняка от этого параметра будут зависеть и характеристики случайной величины.}

\section{Математическое ожидание непрерывной случайной величины}

\exm{5}{
\[\rho_\xi(x) = \begin{cases}
    0, x \notin [a,b], \\
    \dfrac{1}{b-a}, x \in [a,b].
\end{cases}\]
\(\mathbb{M}_\xi = \overset{a}{\underset{-\infty}{\int}}x\rho_\xi(x)dx + \overset{b}{\underset{a}{\int}}x\rho_\xi(x)dx + \overset{+\infty}{\underset{b}{\int}}x\rho_\xi(x)dx = 0 + \overset{b}{\underset{a}{\int}}x\rho_\xi(x)dx + 0 = \overset{b}{\underset{a}{\int}}\dfrac{x}{b-a}dx = \dfrac{b^2 - a^2}{2(b-a)} = \dfrac{a+b}{b-a}\).

\rmk{Мат. ожидание - середина, значит, нам нужна середина отрезка}
}

\subsection{Для показательного распределения}

\exm{6. \(\lambda > 0\)}{
\[\rho_\xi(x) = \begin{cases}
    0, x < 0, \\
    \lambda e^{-\lambda x}, x \geq 0.
\end{cases}\]
\(\mathbb{M}_\xi = \overset{0}{\underset{-\infty}{\int}}x\rho_\xi(x)dx + \overset{+\infty}{\underset{0}{\int}}x\rho_\xi(x)dx = 0 + \overset{+\infty}{\underset{0}{\int}}x\rho_\xi(x)dx = \overset{+\infty}{\underset{0}{\int}} \lambda x e^{-\lambda x} dx = \)

Притормозим на этом моменте, дальше нам нужно интегрирование по частям. Какое-то такое:
\begin{center}
    \begin{tabular}{|c|}
         &  \(x = u, \ \lambda e^{-\lambda x} = dv\) \\
         &  \(dx =du, v = -e^{-\lambda x}\)
    \end{tabular}
\end{center}

Тогда наш интеграл превращается в

\(= x \cdot (e^{-\lambda x})|^{+\infty}_0 + \overset{+\infty}{\underset{0}{\int}}e^{-\lambda x}dx =\)

\rmk{
И еще одна вставочка: возьмем производную (по Лапиталю) и получим дробь, которая стремится к 0, потому что \(\dfrac{1}{\infty} \rightarrow 0\)

\(xe^{-\lambda x} => \dfrac{1}{\lambda e^{\lambda x}} \rightarrow 0\)
}

\(= \dfrac{1}{\lambda} \cdot (-e^{-\lambda x})|^{+ \infty}_0 = \dfrac{1}{\lambda}\).
}

\end{document}